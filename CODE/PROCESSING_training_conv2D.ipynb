{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "import pickle\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Convolution2D, MaxPooling2D, Flatten\n",
    "from keras.utils import plot_model\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allocator_type = 'BFC' #A \"Best-fit with coalescing\" algorithm, simplified from a version of dlmalloc.\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "config.gpu_options.allow_growth = True\n",
    "set_session(tf.Session(config=config)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setting():\n",
    "    info = {\n",
    "        'data_path' : \"dataset_training/video_phases_background_removed.pickle\"\n",
    "    }\n",
    "    return info\n",
    "\n",
    "def loaddata(filepath):\n",
    "    with open(filepath, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "    return data\n",
    "\n",
    "def vector_cat(label_name, le):\n",
    "    vec = np.zeros(len(list(le.classes_)))\n",
    "    vec[int(le.transform([label_name]))] = 1\n",
    "    return vec\n",
    "\n",
    "def set_x_y(data):\n",
    "    \n",
    "    labels = list(data.keys())\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(labels)\n",
    "    x = []\n",
    "    y = []\n",
    "    for key in data.keys():\n",
    "        for img in data[key]:\n",
    "            x.append(img)\n",
    "            y.append(vector_cat(key, le))\n",
    "    return x,y, le\n",
    "## Setting\n",
    "info = setting()\n",
    "data = loaddata(info['data_path'])\n",
    "x, y, le = set_x_y(data)\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.33)\n",
    "train_x=np.asarray(train_x)\n",
    "test_x=np.asarray(test_x)\n",
    "train_y=np.asarray(train_y)\n",
    "test_y=np.asarray(test_y)\n",
    "\n",
    "train_x = train_x.reshape(-1, 1,200, 230)/255\n",
    "test_x = test_x.reshape(-1, 1,200, 230)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training----------\n",
      "Epoch 1/150\n",
      "7562/7562 [==============================] - 16s 2ms/step - loss: 0.7416 - acc: 0.6912\n",
      "Epoch 2/150\n",
      "7562/7562 [==============================] - 11s 2ms/step - loss: 0.2700 - acc: 0.8939\n",
      "Epoch 3/150\n",
      "7562/7562 [==============================] - 11s 2ms/step - loss: 0.2127 - acc: 0.9111\n",
      "Epoch 4/150\n",
      "7562/7562 [==============================] - 11s 2ms/step - loss: 0.1861 - acc: 0.9267\n",
      "Epoch 5/150\n",
      "7562/7562 [==============================] - 12s 2ms/step - loss: 0.1415 - acc: 0.9390\n",
      "Epoch 6/150\n",
      "7562/7562 [==============================] - 12s 2ms/step - loss: 0.1107 - acc: 0.9508\n",
      "Epoch 7/150\n",
      "7562/7562 [==============================] - 12s 2ms/step - loss: 0.1004 - acc: 0.9583\n",
      "Epoch 8/150\n",
      "7562/7562 [==============================] - 12s 2ms/step - loss: 0.0947 - acc: 0.9550\n",
      "Epoch 9/150\n",
      "7562/7562 [==============================] - 12s 2ms/step - loss: 0.0928 - acc: 0.9562\n",
      "Epoch 10/150\n",
      "7562/7562 [==============================] - 12s 2ms/step - loss: 0.0812 - acc: 0.9635\n",
      "Epoch 11/150\n",
      "7562/7562 [==============================] - 12s 2ms/step - loss: 0.0772 - acc: 0.9618\n",
      "Epoch 12/150\n",
      "7562/7562 [==============================] - 12s 2ms/step - loss: 0.0820 - acc: 0.9631\n",
      "Epoch 13/150\n",
      "7562/7562 [==============================] - 12s 2ms/step - loss: 0.0709 - acc: 0.9672\n",
      "Epoch 14/150\n",
      "7562/7562 [==============================] - 12s 2ms/step - loss: 0.0723 - acc: 0.9631\n",
      "Epoch 15/150\n",
      "7562/7562 [==============================] - 12s 2ms/step - loss: 0.0713 - acc: 0.9657\n",
      "Epoch 16/150\n",
      "7562/7562 [==============================] - 12s 2ms/step - loss: 0.0637 - acc: 0.9688\n",
      "Epoch 17/150\n",
      "7562/7562 [==============================] - 12s 2ms/step - loss: 0.0577 - acc: 0.9717\n",
      "Epoch 18/150\n",
      "7562/7562 [==============================] - 12s 2ms/step - loss: 0.0590 - acc: 0.9692\n",
      "Epoch 19/150\n",
      "7562/7562 [==============================] - 12s 2ms/step - loss: 0.0550 - acc: 0.9722\n",
      "Epoch 20/150\n",
      "7562/7562 [==============================] - 12s 2ms/step - loss: 0.0535 - acc: 0.9738\n",
      "Epoch 21/150\n",
      "7562/7562 [==============================] - 12s 2ms/step - loss: 0.0530 - acc: 0.9733\n",
      "Epoch 22/150\n",
      "7562/7562 [==============================] - 12s 2ms/step - loss: 0.0490 - acc: 0.9738\n",
      "Epoch 23/150\n",
      "7562/7562 [==============================] - 12s 2ms/step - loss: 0.0478 - acc: 0.9751\n",
      "Epoch 24/150\n",
      "7562/7562 [==============================] - 12s 2ms/step - loss: 0.0477 - acc: 0.9757\n",
      "Epoch 25/150\n",
      "7562/7562 [==============================] - 12s 2ms/step - loss: 0.0429 - acc: 0.9775\n",
      "Epoch 26/150\n",
      "7562/7562 [==============================] - 12s 2ms/step - loss: 0.0395 - acc: 0.9777\n",
      "Epoch 27/150\n",
      "7562/7562 [==============================] - 12s 2ms/step - loss: 0.0481 - acc: 0.9758\n",
      "Epoch 28/150\n",
      "7562/7562 [==============================] - 12s 2ms/step - loss: 0.0451 - acc: 0.9774\n",
      "Epoch 29/150\n",
      "7562/7562 [==============================] - 12s 2ms/step - loss: 0.0402 - acc: 0.9773\n",
      "Epoch 30/150\n",
      "7562/7562 [==============================] - 12s 2ms/step - loss: 0.0387 - acc: 0.9790\n",
      "Epoch 31/150\n",
      "7562/7562 [==============================] - 12s 2ms/step - loss: 0.0350 - acc: 0.9807\n",
      "Epoch 32/150\n",
      "7562/7562 [==============================] - 12s 2ms/step - loss: 0.0465 - acc: 0.9780\n",
      "Epoch 33/150\n",
      "7562/7562 [==============================] - 12s 2ms/step - loss: 0.0321 - acc: 0.9821\n",
      "Epoch 34/150\n",
      "7562/7562 [==============================] - 12s 2ms/step - loss: 0.0355 - acc: 0.9802\n",
      "Epoch 35/150\n",
      "7562/7562 [==============================] - 12s 2ms/step - loss: 0.0351 - acc: 0.9808\n",
      "Epoch 36/150\n",
      "7562/7562 [==============================] - 12s 2ms/step - loss: 0.0310 - acc: 0.9811\n",
      "Epoch 37/150\n",
      "7562/7562 [==============================] - 12s 2ms/step - loss: 0.0281 - acc: 0.9833\n",
      "Epoch 38/150\n",
      "7562/7562 [==============================] - 12s 2ms/step - loss: 0.0276 - acc: 0.9825\n",
      "Epoch 39/150\n",
      "7562/7562 [==============================] - 12s 2ms/step - loss: 0.0278 - acc: 0.9837\n",
      "Epoch 40/150\n",
      "7562/7562 [==============================] - 12s 2ms/step - loss: 0.0324 - acc: 0.9815\n",
      "Epoch 41/150\n",
      "7562/7562 [==============================] - 12s 2ms/step - loss: 0.0344 - acc: 0.9828\n",
      "Epoch 42/150\n",
      "7562/7562 [==============================] - 12s 2ms/step - loss: 0.0319 - acc: 0.9831\n",
      "Epoch 43/150\n",
      "7562/7562 [==============================] - 12s 2ms/step - loss: 0.0327 - acc: 0.9819\n",
      "Epoch 44/150\n",
      "7562/7562 [==============================] - 12s 2ms/step - loss: 0.0357 - acc: 0.9802\n",
      "Epoch 45/150\n",
      "7562/7562 [==============================] - 12s 2ms/step - loss: 0.0541 - acc: 0.9765\n",
      "Epoch 46/150\n",
      "7562/7562 [==============================] - 12s 2ms/step - loss: 0.0593 - acc: 0.9763\n",
      "Epoch 47/150\n",
      "7562/7562 [==============================] - 12s 2ms/step - loss: 0.0487 - acc: 0.9794\n",
      "Epoch 48/150\n",
      "7562/7562 [==============================] - 12s 2ms/step - loss: 0.0386 - acc: 0.9803\n",
      "Epoch 49/150\n",
      "7562/7562 [==============================] - 12s 2ms/step - loss: 0.0343 - acc: 0.9802\n",
      "Epoch 50/150\n",
      "7562/7562 [==============================] - 12s 2ms/step - loss: 0.0306 - acc: 0.9815\n",
      "Epoch 51/150\n",
      "7562/7562 [==============================] - 12s 2ms/step - loss: 0.0305 - acc: 0.9804\n",
      "Epoch 52/150\n",
      "3400/7562 [============>.................] - ETA: 6s - loss: 0.0296 - acc: 0.9847"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-0b7376ea7071>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;31m# Fit the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Training----------'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;31m# evaluate the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\nTesting----------'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\py37\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\py37\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\py37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\py37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\py37\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# main\n",
    "## Learning\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(batch_input_shape=(None, 1, 200, 230),filters=32,kernel_size=5,strides=1,padding='same', data_format='channels_first'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=2, strides=2, padding='same',data_format='channels_first'))\n",
    "model.add(Convolution2D(64, 5, strides=1, padding='same',data_format='channels_first'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(2, 2, 'same', data_format='channels_first'))\n",
    "model.add(Convolution2D(64, 5, strides=1, padding='same',data_format='channels_first'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(2, 2, 'same', data_format='channels_first'))\n",
    "model.add(Convolution2D(64, 5, strides=1, padding='same',data_format='channels_first'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(2, 2, 'same', data_format='channels_first'))\n",
    "model.add(Convolution2D(64, 5, strides=1, padding='same',data_format='channels_first'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(2, 2, 'same', data_format='channels_first'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1000))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(len(le.classes_)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# Fit the model\n",
    "print('Training----------')\n",
    "model.fit(train_x, train_y, epochs=150, batch_size=100)\n",
    "# evaluate the model\n",
    "print('\\nTesting----------')\n",
    "loss, accuracy = model.evaluate(test_x, test_y)\n",
    "\n",
    "print('\\ntest loss: ', loss)\n",
    "print('\\ntest accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing----------\n",
      "3726/3726 [==============================] - 3s 841us/step\n",
      "\n",
      "test loss:  0.1131247414962873\n",
      "\n",
      "test accuracy:  0.954106280097255\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# evaluate the model\n",
    "print('\\nTesting----------')\n",
    "loss, accuracy = model.evaluate(test_x, test_y)\n",
    "\n",
    "print('\\ntest loss: ', loss)\n",
    "print('\\ntest accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('seq_acu_95.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model.predict(np.array([test_x[1]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 1.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('seq_acu_95_train_x.pickle','wb') as file:\n",
    "    pickle.dump(train_x, file)\n",
    "with open('seq_acu_95_train_y.pickle','wb') as file:\n",
    "    pickle.dump(train_y, file)\n",
    "with open('seq_acu_95_test_x.pickle','wb') as file:\n",
    "    pickle.dump(test_x, file)\n",
    "with open('seq_acu_95_test_y.pickle','wb') as file:\n",
    "    pickle.dump(test_y, file)\n",
    "    \n",
    "with open('seq_acu_95_encoder.pickle','wb') as file:\n",
    "    pickle.dump(le, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "1. [莫煩的 CNN example](https://github.com/MorvanZhou/tutorials/blob/master/kerasTUT/6-CNN_example.py)\n",
    "2. [莫煩的 CNN 解說](https://morvanzhou.github.io/tutorials/machine-learning/keras/2-3-CNN/)\n",
    "3. [GPU 設定](https://blog.csdn.net/u010420283/article/details/85261633)\n",
    "# Trial and error\n",
    "- 如果 Maxpooling 太少, 會導致記憶體不夠\n",
    "    - Maxpooling 會維持二維\n",
    "    - Maxpooling 交替 covlution2D\n",
    "    - 持續增加 maxpooling, 方可解決 \n",
    "\n",
    "# Procedure\n",
    "- Encode\n",
    "    - OneHotEncoding\n",
    "- Training\n",
    "    - Maxpooling 會維持二維\n",
    "    - Maxpooling 交替 covlution2D\n",
    "    - Flatten\n",
    "    - Dense\n",
    "    - Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
